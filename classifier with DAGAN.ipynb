{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2, style=\"ticks\")\n",
    "\n",
    "# my code\n",
    "import misc\n",
    "import gan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSC_ids = np.load(\"data/HSC_ids.npy\")\n",
    "HSC_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"data/images.small.npy\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img = X.copy().transpose([0,2,3,1])\n",
    "X_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = X.shape[-1]\n",
    "image_shape = X.shape[1:]\n",
    "image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/2018_02_23-all_objects.csv\")\n",
    "df = df[df.selected]\n",
    "\n",
    "df = df.drop_duplicates(\"HSC_id\") \\\n",
    "       .set_index(\"HSC_id\") \\\n",
    "       .loc[HSC_ids] \\\n",
    "       [[\"photo_z\", \"log_mass\"]]\n",
    "    \n",
    "\n",
    "targets = (df.log_mass > 8) & (df.log_mass < 9) & (df.photo_z < .15)\n",
    "print(targets.mean())\n",
    "print(targets.sum())\n",
    "\n",
    "y_conditionals = df.values\n",
    "\n",
    "y_conditionals_for_visualization = np.array([[.14, 8.51]])\n",
    "\n",
    "\n",
    "# values copied from output of `simple gan.ipynb`\n",
    "standardizer = misc.Standardizer(means = np.array([0.21093612, 8.62739865]),\n",
    "                                 std = np.array([0.30696933, 0.63783586]))\n",
    "# standardizer.train(y)\n",
    "print(\"means: \", standardizer.means)\n",
    "print(\"std:   \", standardizer.std)\n",
    "\n",
    "\n",
    "y_conditionals = standardizer(y_conditionals)\n",
    "y_conditionals_for_visualization = standardizer(y_conditionals_for_visualization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Split training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "\n",
    "randomized_indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(randomized_indices)\n",
    "\n",
    "training_fraction = 0.8\n",
    "# make sure training set size is an even multiple of 64\n",
    "num_training = (int(training_fraction*X.shape[0]) // batch_size) * batch_size\n",
    "\n",
    "training_set_indices = randomized_indices[:int(num_training)]\n",
    "testing_set_indices = np.array(list(set([*randomized_indices]) - set([*training_set_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set_indices.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_indices.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup GAN augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import Iterator\n",
    "from keras.preprocessing.image import array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAGANIterator(Iterator):\n",
    "    \"\"\"Iterator yielding data from a DAGAN\n",
    "    # Arguments\n",
    "        gan_model: conditional GAN object.\n",
    "        y_target: Numpy array of targets data.\n",
    "        y_conditional: Numpy array of conditionals data (for GAN)\n",
    "            to do: it would be nice to allow this to be a generator.\n",
    "        batch_size: Integer, size of a batch.\n",
    "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "        seed: Random seed for data shuffling.\n",
    "        data_format: String, one of `channels_first`, `channels_last`.\n",
    "        save_to_dir: Optional directory where to save the pictures\n",
    "            being yielded, in a viewable format. This is useful\n",
    "            for visualizing the random transformations being\n",
    "            applied, for debugging purposes.\n",
    "        save_prefix: String prefix to use for saving sample\n",
    "            images (if `save_to_dir` is set).\n",
    "        save_format: Format to use for saving sample images\n",
    "            (if `save_to_dir` is set).\n",
    "        image_shape: array-like, length 3\n",
    "            example: [3, 50, 50]\n",
    "            required since I'm not passing any example images to this object\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gan_model, \n",
    "                 y_target, y_conditional,\n",
    "                 batch_size=64, shuffle=False, seed=None,\n",
    "                 data_format=\"channels_first\",\n",
    "                 save_to_dir=None, save_prefix='', save_format='png',\n",
    "                 image_shape=None):\n",
    "        if data_format is None:\n",
    "            raise ValueError(\"`data_format` cannot be None.\")\n",
    "        self.gan_model = gan_model\n",
    "        channels_axis = 3 if data_format == 'channels_last' else 1\n",
    "        if y_target is not None:\n",
    "            self.y_target = np.asarray(y_target)\n",
    "        else:\n",
    "            self.y_target = None\n",
    "        if y_conditional is not None:\n",
    "            self.y_conditional = np.asarray(y_conditional)\n",
    "        else:\n",
    "            self.y_conditional = None\n",
    "        self.data_format = data_format\n",
    "        self.save_to_dir = save_to_dir\n",
    "        self.save_prefix = save_prefix\n",
    "        self.save_format = save_format\n",
    "        if image_shape is None:\n",
    "            raise ValueError(\"`image_shape` must be array-like of length 3\")\n",
    "        self.image_shape = image_shape\n",
    "        \n",
    "        if batch_size != self.gan_model.batch_size:\n",
    "            raise ValueError(\"DAGANIterator batch_size must match self.gan_model.batch_size.\")\n",
    "        super(DAGANIterator, self).__init__(y_target.shape[0], batch_size, shuffle, seed)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):        \n",
    "        y_conditionals = self.y_conditional[index_array]\n",
    "\n",
    "        batch_x = self.gan_model.generate_samples(y_conditionals)\n",
    "        \n",
    "        batch_x = np.asarray(batch_x, dtype=K.floatx())\n",
    "        batch_x = batch_x.transpose([0,3,1,2])\n",
    "        \n",
    "        if self.save_to_dir:\n",
    "            for i, j in enumerate(index_array):\n",
    "                img = array_to_img(batch_x[i], self.data_format, scale=True)\n",
    "                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n",
    "                                                                  index=j,\n",
    "                                                                  hash=np.random.randint(1e4),\n",
    "                                                                  format=self.save_format)\n",
    "                img.save(os.path.join(self.save_to_dir, fname))\n",
    "        if self.y_target is None:\n",
    "            return batch_x\n",
    "        batch_y = self.y_target[index_array]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        return self._get_batches_of_transformed_samples(index_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "train = False\n",
    "if train:\n",
    "    num_epochs = 450\n",
    "    # use a dir outside of dropbox\n",
    "    checkpoint_dir = os.path.join(os.path.expanduser(\"~\"),\n",
    "                                  \"tmp - models\",\n",
    "                                  \"models/gan/checkpoints\")\n",
    "else:\n",
    "    num_epochs = 1\n",
    "    # use a dir inside the repo\n",
    "    checkpoint_dir = \"models/gan/checkpoints\"\n",
    "\n",
    "# batch_size = 64 # set above\n",
    "z_dim = 100\n",
    "dataset_name = \"galaxy\"\n",
    "result_dir = \"models/gan/results\"\n",
    "log_dir = \"models/gan/log\"\n",
    "\n",
    "gan_model = gan.CGAN(sess, num_epochs, batch_size, z_dim, dataset_name,\n",
    "                     image_size, X_img, \n",
    "                     y_conditionals, y_conditionals_for_visualization,\n",
    "                     checkpoint_dir, result_dir, log_dir,\n",
    "                     d_learning_rate=.0001,\n",
    "                     relative_learning_rate=4.,\n",
    "                    )\n",
    "\n",
    "gan_model.build_model()\n",
    "gan_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_conditional_training = y_conditionals[training_set_indices]\n",
    "y_target_training = targets.values[training_set_indices]\n",
    "\n",
    "y_target_training.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dagan_iterator = DAGANIterator(gan_model, y_target_training, y_conditional_training,\n",
    "                               image_shape=image_shape, \n",
    "                               shuffle=True,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_idx = np.arange(64)\n",
    "\n",
    "y_conditionals_tmp = y_conditionals[batch_idx]\n",
    "\n",
    "samples = gan_model.generate_samples(y_conditionals_tmp)\n",
    "\n",
    "plt.imshow(misc.transform_0_1(samples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup `keras` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_conv_filters = 16\n",
    "conv_kernel_size = 4\n",
    "input_shape = X.shape[1:]\n",
    "\n",
    "dropout_fraction = .25\n",
    "\n",
    "nb_dense = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(n_conv_filters, conv_kernel_size,\n",
    "                        padding='same', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "\n",
    "model.add(Conv2D(n_conv_filters, conv_kernel_size*2,\n",
    "                        padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "model.add(Conv2D(n_conv_filters, conv_kernel_size*4,\n",
    "                        padding='same', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2*nb_dense, activation=\"relu\"))\n",
    "model.add(Dense(nb_dense, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "adam = Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=adam,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor='loss',\n",
    "                              patience=35,\n",
    "                              verbose=1,\n",
    "                              mode='auto' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Basic Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_batch_size = 64\n",
    "steps_per_epoch = max(2, training_set_indices.size//goal_batch_size)\n",
    "batch_size = training_set_indices.size//steps_per_epoch\n",
    "print(\"steps_per_epoch: \", steps_per_epoch)\n",
    "print(\"batch_size: \", batch_size)\n",
    "epochs = 100\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = targets[HSC_ids].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%timeit -r 1 -n 1\n",
    "history = model.fit_generator(dagan_iterator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=epochs,\n",
    "                              validation_data=(X[testing_set_indices], Y[testing_set_indices]),\n",
    "                              verbose=verbose,\n",
    "                              callbacks=[earlystopping],\n",
    "                              )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best performance: \", min(history.history[\"val_loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mpl.rc_context(rc={\"figure.figsize\": (10,6)}):\n",
    "\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation\")\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training\")\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(\"Loss\\n(avg. binary cross-entropy)\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "\n",
    "    \n",
    "    plt.ylim(.45, .65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = model.predict_proba(X[testing_set_indices]).flatten()\n",
    "class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mpl.rc_context(rc={\"figure.figsize\": (10,6)}):\n",
    "    sns.distplot(class_probs[Y[testing_set_indices]==True], color=\"g\", label=\"true dwarfs\")\n",
    "    sns.distplot(class_probs[Y[testing_set_indices]==False], color=\"b\", label=\"true non-dwarfs\")\n",
    "\n",
    "    plt.xlabel(\"p(dwarf | image)\")\n",
    "    plt.ylabel(\"density (galaxies)\")\n",
    "\n",
    "    plt.xlim(0, .7)\n",
    "    plt.axvline(Y[training_set_indices].mean(), linestyle=\"dashed\", color=\"black\", label=\"prior\\n(from training set)\")\n",
    "    plt.axvline(.5, linestyle=\"dotted\", color=\"black\", label=\"50/50\")\n",
    "\n",
    "    plt.legend(\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(1, 1),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "with mpl.rc_context(rc={\"figure.figsize\": (10,6)}):\n",
    "    fpr, tpr, _ = metrics.roc_curve(Y[testing_set_indices], class_probs)\n",
    "    roc_auc = roc_auc_score(Y[testing_set_indices], class_probs)\n",
    "\n",
    "    plt.plot(fpr, tpr, label=\"DNN (AUC = {:.2})\".format(roc_auc))\n",
    "    plt.plot([0,1], [0,1], linestyle=\"dashed\", color=\"black\", label=\"random guessing\")\n",
    "\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "    plt.title(\"ROC Curve\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import average_precision_score\n",
    "with mpl.rc_context(rc={\"figure.figsize\": (10,6)}):\n",
    "    precision, recall, _ = metrics.precision_recall_curve(Y[testing_set_indices], class_probs)\n",
    "    pr_auc = average_precision_score(Y[testing_set_indices], class_probs)\n",
    "\n",
    "    plt.plot(recall, precision, label=\"AUC = {:.2}\".format(pr_auc))\n",
    "    plt.plot([0,1], [Y[testing_set_indices].mean()]*2, linestyle=\"dashed\", color=\"black\")\n",
    "\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "\n",
    "    plt.title(\"PR Curve\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
