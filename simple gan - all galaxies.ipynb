{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "mpl.rcParams['figure.figsize'] = np.array((10,6))*.6\n",
    "\n",
    "# my code\n",
    "import misc\n",
    "import gan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load galaxy image data\n",
    "If you need the `.npy` files, download them from [this directory](https://www.dropbox.com/sh/raq8y8wt2rii7d6/AACA6OO3eKxfTevTJj19w_rea?dl=0). It'll be called `npy_files.tar.gz`; I'd link to it directly, but it hasn't uploaded to dropbox yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"data/galaxy_images_training/npy_files/\"\n",
    "filename_formatter = os.path.join(img_dir, \"{}-cutout.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_files = glob.glob(filename_formatter.format(\"*\"))\n",
    "\n",
    "HSC_ids = np.array([int(os.path.basename(f).split(\"-\")[0])\n",
    "                    for f in npy_files])\n",
    "\n",
    "HSC_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img = np.empty([len(HSC_ids), 3, 50, 50])\n",
    "for i, HSC_id in enumerate(HSC_ids):\n",
    "    X_img[i] = np.load(filename_formatter.format(HSC_id))\n",
    "\n",
    "X_img = X_img.transpose([0,2,3,1])\n",
    "X_img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = X_img.shape[1]\n",
    "image_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load targets\n",
    "`HSC_ids` are in the same order as the `X_img` data. These ids are then used to cross-reference the table read into `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/2018_02_23-all_objects.csv\")\n",
    "# df = df[df.selected]\n",
    "\n",
    "\n",
    "df = df.drop_duplicates(\"HSC_id\") \\\n",
    "       .set_index(\"HSC_id\") \\\n",
    "       [[\"photo_z\", \"log_mass\"]]\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[HSC_ids].values\n",
    "y_for_visualization_samples = np.array([.14, 8.51])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values copied from output of `simple gan.ipynb`\n",
    "standardizer = misc.Standardizer(means = np.array([0.21093612, 8.62739865]),\n",
    "                                 std = np.array([0.30696933, 0.63783586]))\n",
    "# standardizer.train(y)\n",
    "print(\"means: \", standardizer.means)\n",
    "print(\"std:   \", standardizer.std)\n",
    "y_standard = standardizer(y)\n",
    "y_for_visualization_samples_standard = standardizer(y_for_visualization_samples)\n",
    "\n",
    "y_standard.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run GAN\n",
    "Modeled after: https://github.com/hwalsuklee/tensorflow-generative-model-collections/blob/f24a27feba327a1086298a810fdf83bb30d5128a/CGAN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_threads = 4\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=num_threads,\n",
    "    inter_op_parallelism_threads=num_threads,\n",
    "))\n",
    "\n",
    "train = True\n",
    "if train:\n",
    "    num_epochs = 100\n",
    "    # use a dir outside of dropbox\n",
    "    checkpoint_dir = os.path.join(os.path.expanduser(\"~\"),\n",
    "                                  \"tmp - models\",\n",
    "                                  \"models/gan/checkpoints\")\n",
    "else:\n",
    "    num_epochs = 1\n",
    "    # use a dir inside the repo\n",
    "    checkpoint_dir = \"models/gan/checkpoints\"\n",
    "    \n",
    "batch_size = 64\n",
    "z_dim = 100\n",
    "dataset_name = \"galaxy_all\"\n",
    "result_dir = \"models/gan/results\"\n",
    "log_dir = \"models/gan/log\"\n",
    "\n",
    "model = gan.CGAN(sess, num_epochs, batch_size, z_dim, dataset_name,\n",
    "                 image_size, X_img, \n",
    "                 y_standard, y_for_visualization_samples_standard,\n",
    "                 checkpoint_dir, result_dir, log_dir,\n",
    "                 d_learning_rate=.0001,\n",
    "                 relative_learning_rate=4.,\n",
    "                 loss_weighting=50.,\n",
    "                )\n",
    "\n",
    "model.build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
